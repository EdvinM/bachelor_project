{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.logic import simplify_logic\n",
    "from sympy.abc import x, y, z\n",
    "from sympy import *\n",
    "from sympy.logic.boolalg import *\n",
    "from sympy.logic.inference import satisfiable\n",
    "\n",
    "from pyeda.inter import *\n",
    "from itertools import product\n",
    "from pypred import OptimizedPredicateSet, PredicateSet, Predicate\n",
    "from collections import OrderedDict\n",
    "\n",
    "import uuid\n",
    "import operator\n",
    "\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "def viz_tree(clf, class_names, feature_names):\n",
    "    tree_ = tree.export_graphviz(clf, out_file = None, filled=True, rounded=True, class_names=class_names, feature_names=feature_names)\n",
    "    graph = graphviz.Source(tree_)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def get_truth(inp, relate, cut):\n",
    "    ops = {'>': operator.gt,\n",
    "           '<': operator.lt,\n",
    "           '>=': operator.ge,\n",
    "           '<=': operator.le,\n",
    "           '=': operator.eq}\n",
    "    return ops[relate](inp, cut)\n",
    "\n",
    "\n",
    "def get_leaf_class_name(class_names, node_values):\n",
    "    max_value_index = 0\n",
    "    max_value = 0\n",
    "    for c, value in enumerate(node_values[0]):\n",
    "        if value != 0 and value > max_value:\n",
    "            max_value_index = c\n",
    "            max_value = value\n",
    "    \n",
    "    return class_names[max_value_index]\n",
    "\n",
    "        \n",
    "def get_node_value(node_values):\n",
    "    max_ = 0\n",
    "    for c, value in enumerate(node_values[0]):\n",
    "        if value > max_:\n",
    "            max_ = value\n",
    "            \n",
    "    return max_\n",
    "        \n",
    "        \n",
    "def get_paths_for(class_name, tree, cur_index, lst, paths, sign):\n",
    "    if cur_index >= len(tree.children_left):\n",
    "        return\n",
    "    \n",
    "    if len(lst) > 0 and cur_index != -1:\n",
    "        lst[len(lst) - 1] = (lst[len(lst) - 1][0], lst[len(lst) - 1][1], sign, lst[len(lst) - 1][3])\n",
    "        \n",
    "    lst.append((cur_index, tree.feature[cur_index], sign, round(tree.threshold[cur_index], 2)))\n",
    "    if cur_index != -1:\n",
    "        get_paths_for(class_name, tree, tree.children_left[cur_index], lst, paths, '<=')\n",
    "        get_paths_for(class_name, tree, tree.children_right[cur_index], lst, paths, '>')\n",
    "    else:\n",
    "        if get_leaf_class_name(data['class'].unique(), tree.value[list(lst[-2])[0]]) == class_name:\n",
    "            paths.add(tuple(lst[:-1]))\n",
    "        \n",
    "    lst.pop()\n",
    "    \n",
    "    \n",
    "def get_feature_value_pairs(tree, paths):\n",
    "    \n",
    "    pairs = []\n",
    "    for path in paths:\n",
    "        d = []\n",
    "        features = tree.feature\n",
    "        thresholds = tree.threshold\n",
    "\n",
    "        for i, p in enumerate(list(path[:-1])):\n",
    "            d.append((i, features[i], thresholds[i]))\n",
    "\n",
    "        pairs.append(d)\n",
    "        \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def rule_predict(class_name, rule):\n",
    "    pred = []\n",
    "    \n",
    "    for row in X_validation:\n",
    "        \n",
    "        valid = True\n",
    "        for condition in rule[:-1]:\n",
    "            condition = list(condition)\n",
    "            \n",
    "            if not get_truth(row[condition[1]], condition[2], condition[3]):\n",
    "                valid = False\n",
    "            \n",
    "        if valid:\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "# Function which computes rule accuracy based. It makes a classification report and takes\n",
    "# the precision value and returns it\n",
    "def compute_rule_accuracy(class_name, rule):\n",
    "    pred = rule_predict(class_name, rule)\n",
    "    report = classification_report(pred, Y_validation, output_dict = True)\n",
    "    \n",
    "    return round(report[str(class_name)]['precision'], 2)\n",
    "\n",
    "\n",
    "def prune_rule(class_name, rule):\n",
    "    max_accuracy = 0\n",
    "    final_rule = rule\n",
    "    \n",
    "    for i in range(len(rule[:-1])):\n",
    "        accuracy = compute_rule_accuracy(class_name, rule[i:])\n",
    "        \n",
    "        if accuracy > max_accuracy:\n",
    "            final_rule = rule[i:]\n",
    "            max_accuracy = accuracy\n",
    "           \n",
    "    return (max_accuracy, tuple(final_rule))\n",
    "\n",
    "\n",
    "def combine_rules(class_name, rf_model):\n",
    "    rules = set()\n",
    "    \n",
    "    for estimator in rf_model.estimators_:\n",
    "        get_paths_for(class_name, estimator.tree_, 0, [], rules, '<=')\n",
    "        \n",
    "    return rules\n",
    "\n",
    "\n",
    "def get_class_index(class_name):\n",
    "    for c, cls in enumerate(data['class'].unique()):\n",
    "        if cls == class_name:\n",
    "            return c\n",
    "        \n",
    "        \n",
    "def get_rules_accuracy(class_name, rf_model, removeRedundancy = False):\n",
    "    rules = combine_rules(class_name, rf_model)\n",
    "    \n",
    "    if removeRedundancy:\n",
    "        rules = redundancy_condition_removal(rules)\n",
    "    \n",
    "    rules = list(rules)\n",
    "    \n",
    "    final_rules = set()\n",
    "    for rule in rules:\n",
    "        rule_ = [compute_rule_accuracy(get_class_index(class_name), rule), rule]\n",
    "        final_rules.add(tuple(rule_))\n",
    "        \n",
    "    return sorted(list(final_rules), reverse=True, key=lambda x: list(x)[0])\n",
    "    \n",
    "        \n",
    "def get_pruned_rules_accuracy(class_name, rf_model):\n",
    "    rules = list(combine_rules(class_name, rf_model))\n",
    "    \n",
    "    final_rules = set()\n",
    "    for rule in rules:\n",
    "        pruned = prune_rule(get_class_index(class_name), list(rule))\n",
    "        final_rules.add(tuple(pruned))\n",
    "    \n",
    "    return sorted(list(final_rules), reverse=True, key=lambda x: list(x)[0])\n",
    "\n",
    "\n",
    "def redundancy_condition_removal(rule_set):\n",
    "    output = set()\n",
    "    \n",
    "    for rule in list(rule_set):\n",
    "        \n",
    "        rule = list(rule)\n",
    "        for i, cond in enumerate(rule[:-1]):\n",
    "            cond = list(cond)\n",
    "            \n",
    "            for cond2 in rule[i + 1:-1]:\n",
    "                cond2 = list(cond2)\n",
    "                    \n",
    "                if cond[1] == cond2[1] and cond[2] == cond2[2]:\n",
    "                    if cond[2] == '>':\n",
    "                        cond[3] = (cond[3] if cond[3] > cond2[3] else cond2[3])\n",
    "                    else:\n",
    "                        cond[3] = (cond[3] if cond[3] < cond2[3] else cond2[3])\n",
    "                        \n",
    "                    # Assign changed rule to condition\n",
    "                    rule[i] = tuple(cond)\n",
    "                    \n",
    "                    # Remove redundant rule from list\n",
    "                    rule.remove(tuple(cond2))\n",
    "                \n",
    "        output.add(tuple(rule))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def create_big_or_rule(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += create_and_expression(rule)\n",
    "        \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" | \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def create_big_and_rule(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += create_and_expression(rule)\n",
    "        \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" & \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def combine_rule_using_and(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += \"(\" + rule + \")\"\n",
    "            \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" & \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def combine_forest_rules(rf_model, class_name, r_dict, v_dict):\n",
    "    final_rule = set()\n",
    "    simplified_final_rule = set()\n",
    "    for estimator in rf_model.estimators_:\n",
    "    \n",
    "        rules = set()\n",
    "        get_paths_for(class_name, estimator.tree_, 0, [], rules, '<=')\n",
    "        \n",
    "        rules = redundancy_condition_removal(rules)\n",
    "        tree_rule = sympify(create_big_or_rule(rules), evaluate=False)\n",
    "        print(tree_rule)\n",
    "        \n",
    "        final_rule.add(str(tree_rule))\n",
    "        simplified_final_rule.add(str(simplify_logic(tree_rule)))\n",
    "        \n",
    "        \n",
    "    return final_rule, simplified_final_rule\n",
    "\n",
    "\n",
    "def create_and_expression(rule):\n",
    "    output = \"\"\n",
    "    \n",
    "    for i, condition in enumerate(list(rule)[:-1]):\n",
    "        condition = list(condition)\n",
    "        key = str(condition[1]) + str(condition[3])\n",
    "        \n",
    "        var = \"A\" + uuid.uuid4().hex[:6].upper()\n",
    "        \n",
    "        if key in rule_dict:\n",
    "            if condition[2] != rule_dict[key][0]:\n",
    "                output += \"Not(\" + rule_dict[key][1] + \")\"\n",
    "            else:\n",
    "                output += rule_dict[key][1]\n",
    "        else:\n",
    "            expr = var + ' = ' + 'symbols(\\'' + (str(condition[1]) + condition[2] + str(condition[3])) + '\\')'\n",
    "            exec(expr)\n",
    "            \n",
    "            rule_dict[key] = [condition[2], var]\n",
    "            output += var\n",
    "        \n",
    "            # Also push to rule_dict where key is the variable name and value is the rule\n",
    "            var_dict[var] = condition\n",
    "        \n",
    "        if len(list(rule)[:-1]) - 1 != i:\n",
    "            output += \" & \"\n",
    "        \n",
    "    return \"(\" + output + \")\"\n",
    "\n",
    "\n",
    "def print_final_rule(simplified_rule):\n",
    "    simplified_rule = str(simplified_rule).split()\n",
    "    \n",
    "    final_rule = \"\"\n",
    "    for el in simplified_rule:\n",
    "        if el in ('&', '|'):\n",
    "            final_rule += \" \" + el + \" \"\n",
    "        else:\n",
    "            if \"~\" in el:\n",
    "                el = el.replace(\"~\", \"\")\n",
    "                el_ = el\n",
    "                \n",
    "                lb_count = el_.count('(')\n",
    "                if \"(\" in el_:\n",
    "                    el_ = el_.replace(\"(\", \"\")\n",
    "                \n",
    "                rb_count = el_.count(')')\n",
    "                if \")\" in el_:\n",
    "                    el_ = el_.replace(\")\", \"\")\n",
    "                \n",
    "                var = var_dict[str(el_)].copy()[1:]\n",
    "                if var[1] == '>':\n",
    "                    var[1] = '<='\n",
    "                else:\n",
    "                    var[1] = '>'\n",
    "                  \n",
    "                if lb_count == 0 and rb_count == 0:\n",
    "                    final_rule += str(tuple(var))\n",
    "                elif lb_count != 0 and rb_count == 0:\n",
    "                    final_rule += (\"(\" * lb_count) + str(tuple(var))\n",
    "                elif lb_count == 0 and rb_count != 0:\n",
    "                    final_rule += str(tuple(var)) + (\")\" * rb_count)\n",
    "            \n",
    "            elif \"(\" in el:\n",
    "                b_count = el.count('(')\n",
    "                \n",
    "                el = el.replace(\"(\", \"\")\n",
    "                final_rule += (\"(\" * b_count) + str(tuple(var_dict[str(el)][1:]))\n",
    "                \n",
    "            elif \")\" in el:\n",
    "                b_count = el.count(')')\n",
    "                \n",
    "                el = el.replace(\")\", \"\")\n",
    "                final_rule += str(tuple(var_dict[str(el)][1:])) + (\")\" * b_count)\n",
    "            \n",
    "            else:\n",
    "                final_rule += str(tuple(var_dict[str(el)][1:]))\n",
    "            \n",
    "    return final_rule\n",
    "\n",
    "\n",
    "def convert_to_function(sign, expr_):\n",
    "    rule = \"\"\n",
    "    for i, el in enumerate(expr_.xs):\n",
    "        if \"And\" in str(el):\n",
    "            rule += \"(\" + convert_to_function(\"&\", el) + \")\"\n",
    "        elif \"Or\" in str(el):\n",
    "            rule += \"(\" + convert_to_function(\"|\", el) + \")\"\n",
    "        else:\n",
    "            rule += str(el)\n",
    "            \n",
    "        if i != len(expr_.xs) - 1:\n",
    "            rule += \" \" + sign + \" \"\n",
    "            \n",
    "    return rule\n",
    "\n",
    "\n",
    "def get_valid_predicate(rule):\n",
    "    rule = rule.replace(\"&\", \"and\").replace(\"|\", \"or\").replace(\"0, '\", 'sepal_length_cm ').replace(\"1, '\", 'sepal_width_cm ')\n",
    "    rule = rule.replace(\"2, '\", 'petal_length_cm ').replace(\"3, '\", 'petal_width_cm ').replace(\"',\", \"\")\n",
    "    \n",
    "    return rule\n",
    "    \n",
    "    \n",
    "def predict_rule_class(rule_set):\n",
    "    X = X_train\n",
    "    Y = Y_train\n",
    "    \n",
    "    Z = predicate_rules_set_predict(rules_set, X_validation)\n",
    "    \n",
    "    print(accuracy_score(Y_validation, Z))\n",
    "    print(classification_report(Z, Y_validation))\n",
    "    \n",
    "    \n",
    "def compute_final_rule_accuracy(class_index, rule):\n",
    "    X = X_validation\n",
    "    Y = Y_validation\n",
    "    \n",
    "    # Classification report\n",
    "    Z = compute_rule_accuracy(class_index, rule, X)\n",
    "\n",
    "    report = classification_report(Z, Y, output_dict = True)\n",
    "    print(report[str(class_index)])\n",
    "    \n",
    "    \n",
    "def compute_rule_accuracy(class_name, rule, dataset):\n",
    "    \"\"\"This method allows you to evaluate the whole rule given by 'rule' parameter to 'class_name'\n",
    "    Returns an array of evaluated rule\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    # Store dataframe attribute names\n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    \n",
    "    # Create an ordered dictionary in order to keep the order when we take values for given columns\n",
    "    d_ = OrderedDict()\n",
    "    \n",
    "    # Create and optimize predicate given by the parameter\n",
    "    test = Predicate(rule)\n",
    "    s = OptimizedPredicateSet([test])\n",
    "    \n",
    "    for row in dataset:\n",
    "        \n",
    "        # Create dictionary consisting of attribute names and corresponding row values for them\n",
    "        for l, at in enumerate(df_columns):\n",
    "            d_[at] = row[l]\n",
    "        \n",
    "        # Evaluate rule with created dictionary\n",
    "        match = s.evaluate(dict(d_))\n",
    "            \n",
    "        # If the conditions from rule were met, append the class to final predictions array\n",
    "        if len(match):\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def attribute_rule_predict(class_name, rule, attr1, attr2, dataset):\n",
    "    \"\"\"Method used to get prediction only for two attributes given by 'attr1' and 'attr2' parameters\n",
    "    This method is mainly used mainly for plotting purposes\n",
    "    \"\"\" \n",
    "    \n",
    "    # Create an empty predictions array\n",
    "    pred = []\n",
    "    \n",
    "    # Create and optimize predicate given by the parameter\n",
    "    test = Predicate(rule)\n",
    "    s = OptimizedPredicateSet([test])\n",
    "    \n",
    "    # Store dataframe attribute names\n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    \n",
    "    # Create dictionary in which we will create the predicate\n",
    "    d_ = dict()\n",
    "    \n",
    "    for row in dataset:\n",
    "        \n",
    "        # Get the attribute names by indexes from df_columns.\n",
    "        d_[df_columns[attr1]] = row[0]\n",
    "        d_[df_columns[attr2]] = row[1]\n",
    "    \n",
    "        # Evaluate rule with created dictionary\n",
    "        match = s.evaluate(d_)\n",
    "            \n",
    "        # If the conditions from rule were met, append the class to final predictions array\n",
    "        if len(match):\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def visualize_decision_boundaries(rule, attr1, attr2):\n",
    "    \"\"\"\n",
    "    This function is used to draw decision boundaries for 2 attributes which will be used to predict the output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dataset from validation data having only columns specified by paramters\n",
    "    X = X_validation[:, [attr1, attr2]]\n",
    "    Y = Y_validation\n",
    "\n",
    "    # Plotting decision regions\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    f, axarr = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Create prediction\n",
    "    ravel_ = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = np.array(attribute_rule_predict(1, rule, attr1, attr2, ravel_))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot predicted dots\n",
    "    axarr.contourf(xx, yy, Z, alpha=0.5)\n",
    "    axarr.scatter(X[:, 0], X[:, 1], c=Y, s=50, edgecolor='k')\n",
    "    axarr.set_title(\"When random forest is very sure\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def predicate_rules_set_predict(rules_set, dataset):\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    d_ = OrderedDict()\n",
    "    \n",
    "    w_set = set()\n",
    "    for r in rules_set:\n",
    "        r = (r[0], OptimizedPredicateSet([Predicate(r[1])]))\n",
    "        w_set.add(r)\n",
    "        \n",
    "    for i, row in enumerate(dataset):\n",
    "        \n",
    "        \n",
    "        for l, at in enumerate(df_columns):\n",
    "            d_[at] = row[l]\n",
    "            \n",
    "        \n",
    "        j = 0\n",
    "        for r in w_set:\n",
    "            class_i = r[0]\n",
    "            rule_p = r[1]\n",
    "\n",
    "            match = rule_p.evaluate(dict(d_))\n",
    "\n",
    "            if len(match):\n",
    "                pred.append(class_i)\n",
    "                break\n",
    "        \n",
    "            j += 1\n",
    "            \n",
    "        if j == len(w_set):\n",
    "            pred.append(-1)\n",
    "        \n",
    "    return pred\n",
    "\n",
    "\n",
    "def redundancy_condition_removal_(rule_set):\n",
    "    output = set()\n",
    "    \n",
    "    for rule in list(rule_set):\n",
    "        \n",
    "        rule = list(rule)\n",
    "        for i, cond in enumerate(rule):\n",
    "            cond = list(cond)\n",
    "            \n",
    "            for cond2 in rule[i + 1:]:\n",
    "                cond2 = list(cond2)\n",
    "                    \n",
    "                if cond[0] == cond2[0] and cond[1] == cond2[1]:\n",
    "                    if cond[1] == '>':\n",
    "                        cond[2] = (cond[2] if cond[2] > cond2[2] else cond2[2])\n",
    "                    else:\n",
    "                        cond[2] = (cond[2] if cond[2] < cond2[2] else cond2[2])\n",
    "                        \n",
    "                    # Assign changed rule to condition\n",
    "                    rule[i] = tuple(cond)\n",
    "                    \n",
    "                    # Remove redundant rule from list\n",
    "                    rule.remove(tuple(cond2))\n",
    "                \n",
    "        output.add(tuple(rule))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def split_rules(rule_str):\n",
    "    redundant_rules_set = set()\n",
    "    composed_rules_set = set()\n",
    "    \n",
    "    rule = \"\"\n",
    "    stack = []\n",
    "    \n",
    "    for c in rule_str:\n",
    "        \n",
    "        if c in (' ', '&', '|') and len(stack) == 0:\n",
    "            continue\n",
    "            \n",
    "        rule += c\n",
    "        \n",
    "        if c == \"(\":\n",
    "            stack.append(c)\n",
    "        \n",
    "        if c == \")\" and len(stack) == 1:\n",
    "            stack.pop()\n",
    "            \n",
    "            if len(stack) == 0:\n",
    "                try:\n",
    "                    redundant_rules_set.add(eval(rule))\n",
    "                except:\n",
    "                    composed_rules_set.add(rule)\n",
    "            \n",
    "            rule = \"\"\n",
    "            \n",
    "        elif c == ')':\n",
    "            stack.pop()\n",
    "            \n",
    "    return redundant_rules_set, composed_rules_set\n",
    "\n",
    "\n",
    "def compose_final_rule(no_redundant_rules, composed_rules_set):\n",
    "    final_rule = \"\"\n",
    "    \n",
    "    for i, rule in enumerate(no_redundant_rules):\n",
    "        final_rule += str(rule) + \" & \"\n",
    "            \n",
    "    for i, rule in enumerate(composed_rules_set):\n",
    "        final_rule += rule\n",
    "        \n",
    "        if len(composed_rules_set) - 1 != i:\n",
    "            final_rule += \" & \"\n",
    "        \n",
    "    return final_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points     ...      Soil_Type32  Soil_Type33  \\\n",
       "0                                6279     ...                0            0   \n",
       "1                                6225     ...                0            0   \n",
       "2                                6121     ...                0            0   \n",
       "3                                6211     ...                0            0   \n",
       "4                                6172     ...                0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/covtype.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      "Elevation                             581012 non-null int64\n",
      "Aspect                                581012 non-null int64\n",
      "Slope                                 581012 non-null int64\n",
      "Horizontal_Distance_To_Hydrology      581012 non-null int64\n",
      "Vertical_Distance_To_Hydrology        581012 non-null int64\n",
      "Horizontal_Distance_To_Roadways       581012 non-null int64\n",
      "Hillshade_9am                         581012 non-null int64\n",
      "Hillshade_Noon                        581012 non-null int64\n",
      "Hillshade_3pm                         581012 non-null int64\n",
      "Horizontal_Distance_To_Fire_Points    581012 non-null int64\n",
      "Wilderness_Area1                      581012 non-null int64\n",
      "Wilderness_Area2                      581012 non-null int64\n",
      "Wilderness_Area3                      581012 non-null int64\n",
      "Wilderness_Area4                      581012 non-null int64\n",
      "Soil_Type1                            581012 non-null int64\n",
      "Soil_Type2                            581012 non-null int64\n",
      "Soil_Type3                            581012 non-null int64\n",
      "Soil_Type4                            581012 non-null int64\n",
      "Soil_Type5                            581012 non-null int64\n",
      "Soil_Type6                            581012 non-null int64\n",
      "Soil_Type7                            581012 non-null int64\n",
      "Soil_Type8                            581012 non-null int64\n",
      "Soil_Type9                            581012 non-null int64\n",
      "Soil_Type10                           581012 non-null int64\n",
      "Soil_Type11                           581012 non-null int64\n",
      "Soil_Type12                           581012 non-null int64\n",
      "Soil_Type13                           581012 non-null int64\n",
      "Soil_Type14                           581012 non-null int64\n",
      "Soil_Type15                           581012 non-null int64\n",
      "Soil_Type16                           581012 non-null int64\n",
      "Soil_Type17                           581012 non-null int64\n",
      "Soil_Type18                           581012 non-null int64\n",
      "Soil_Type19                           581012 non-null int64\n",
      "Soil_Type20                           581012 non-null int64\n",
      "Soil_Type21                           581012 non-null int64\n",
      "Soil_Type22                           581012 non-null int64\n",
      "Soil_Type23                           581012 non-null int64\n",
      "Soil_Type24                           581012 non-null int64\n",
      "Soil_Type25                           581012 non-null int64\n",
      "Soil_Type26                           581012 non-null int64\n",
      "Soil_Type27                           581012 non-null int64\n",
      "Soil_Type28                           581012 non-null int64\n",
      "Soil_Type29                           581012 non-null int64\n",
      "Soil_Type30                           581012 non-null int64\n",
      "Soil_Type31                           581012 non-null int64\n",
      "Soil_Type32                           581012 non-null int64\n",
      "Soil_Type33                           581012 non-null int64\n",
      "Soil_Type34                           581012 non-null int64\n",
      "Soil_Type35                           581012 non-null int64\n",
      "Soil_Type36                           581012 non-null int64\n",
      "Soil_Type37                           581012 non-null int64\n",
      "Soil_Type38                           581012 non-null int64\n",
      "Soil_Type39                           581012 non-null int64\n",
      "Soil_Type40                           581012 non-null int64\n",
      "Cover_Type                            581012 non-null int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "array = data.values\n",
    "X = array[0:, 0:(len(data.columns.values) - 2)]\n",
    "Y = array[:,(len(data.columns.values) - 1)]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "Y_validation = le.fit_transform(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794377081486709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     42524\n",
      "           1       0.79      0.84      0.81     56386\n",
      "           2       0.75      0.85      0.79      7185\n",
      "           3       0.80      0.71      0.75       600\n",
      "           4       0.79      0.23      0.35      1905\n",
      "           5       0.70      0.30      0.42      3456\n",
      "           6       0.87      0.72      0.79      4147\n",
      "\n",
      "   micro avg       0.78      0.78      0.78    116203\n",
      "   macro avg       0.78      0.63      0.67    116203\n",
      "weighted avg       0.78      0.78      0.77    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, pred))\n",
    "print(classification_report(Y_validation, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_array = data.columns.values[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology',\n",
       "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am',\n",
       "       'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4',\n",
       "       'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
       "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
       "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
       "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
       "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
       "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
       "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
       "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
       "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.int64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4a3494bf5215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cover_Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8aa0908ccf3a>\u001b[0m in \u001b[0;36mviz_tree\u001b[0;34m(clf, class_names, feature_names)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mviz_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtree_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# Now recurse the tree and add node & edge attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;31m# If required, draw leaf nodes at same depth as each other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(tree, node_id, criterion, parent, depth)\u001b[0m\n\u001b[1;32m    334\u001b[0m             out_file.write('%d [label=%s'\n\u001b[1;32m    335\u001b[0m                            % (node_id,\n\u001b[0;32m--> 336\u001b[0;31m                               node_to_str(tree, node_id, criterion)))\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mnode_to_str\u001b[0;34m(tree, node_id, criterion)\u001b[0m\n\u001b[1;32m    304\u001b[0m                                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                           characters[2])\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mnode_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Clean up any trailing newlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.int64\") to str"
     ]
    }
   ],
   "source": [
    "viz_tree(clf, data['Cover_Type'].unique(), feature_names_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
