{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ = pd.read_csv('datasets/diamonds.csv')\n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 11 columns):\n",
      "Unnamed: 0    53940 non-null int64\n",
      "carat         53940 non-null float64\n",
      "cut           53940 non-null object\n",
      "color         53940 non-null object\n",
      "clarity       53940 non-null object\n",
      "depth         53940 non-null float64\n",
      "table         53940 non-null float64\n",
      "price         53940 non-null int64\n",
      "x             53940 non-null float64\n",
      "y             53940 non-null float64\n",
      "z             53940 non-null float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data_.drop(['Unnamed: 0', 'clarity', 'color'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "array = data.values\n",
    "Y = data_.pop('cut').values\n",
    "X = data_.values\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "Y_validation = le.fit_transform(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.07, 61.8 , 61.  , ...,  8.12,  8.16,  5.03],\n",
       "       [ 0.62, 62.2 , 54.  , ...,  5.46,  5.51,  3.41],\n",
       "       [ 0.97, 62.9 , 57.  , ...,  6.28,  6.31,  3.96],\n",
       "       ...,\n",
       "       [ 0.41, 60.7 , 59.  , ...,  4.79,  4.77,  2.9 ],\n",
       "       [ 1.05, 62.3 , 56.  , ...,  6.47,  6.54,  4.05],\n",
       "       [ 0.7 , 62.4 , 57.  , ...,  5.64,  5.7 ,  3.54]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.logic import simplify_logic\n",
    "from sympy.abc import x, y, z\n",
    "from sympy import *\n",
    "from sympy.logic.boolalg import *\n",
    "from sympy.logic.inference import satisfiable\n",
    "\n",
    "from pyeda.inter import *\n",
    "from itertools import product\n",
    "from pypred import OptimizedPredicateSet, PredicateSet, Predicate\n",
    "from collections import OrderedDict\n",
    "\n",
    "import uuid\n",
    "import operator\n",
    "\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "def viz_tree(clf, class_names, feature_names):\n",
    "    tree_ = tree.export_graphviz(clf, out_file = None, filled=True, rounded=True, class_names=class_names, feature_names=feature_names)\n",
    "    graph = graphviz.Source(tree_)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def get_truth(inp, relate, cut):\n",
    "    ops = {'>': operator.gt,\n",
    "           '<': operator.lt,\n",
    "           '>=': operator.ge,\n",
    "           '<=': operator.le,\n",
    "           '=': operator.eq}\n",
    "    return ops[relate](inp, cut)\n",
    "\n",
    "\n",
    "def get_leaf_class_name(class_names, node_values):\n",
    "    max_value_index = 0\n",
    "    max_value = 0\n",
    "    for c, value in enumerate(node_values[0]):\n",
    "        if value != 0 and value > max_value:\n",
    "            max_value_index = c\n",
    "            max_value = value\n",
    "    \n",
    "    return class_names[max_value_index]\n",
    "\n",
    "        \n",
    "def get_node_value(node_values):\n",
    "    max_ = 0\n",
    "    for c, value in enumerate(node_values[0]):\n",
    "        if value > max_:\n",
    "            max_ = value\n",
    "            \n",
    "    return max_\n",
    "        \n",
    "        \n",
    "def get_paths_for(class_name, tree, cur_index, lst, paths, sign):\n",
    "    if cur_index >= len(tree.children_left):\n",
    "        return\n",
    "    \n",
    "    if len(lst) > 0 and cur_index != -1:\n",
    "        lst[len(lst) - 1] = (lst[len(lst) - 1][0], lst[len(lst) - 1][1], sign, lst[len(lst) - 1][3])\n",
    "        \n",
    "    lst.append((cur_index, tree.feature[cur_index], sign, round(tree.threshold[cur_index], 2)))\n",
    "    if cur_index != -1:\n",
    "        get_paths_for(class_name, tree, tree.children_left[cur_index], lst, paths, '<=')\n",
    "        get_paths_for(class_name, tree, tree.children_right[cur_index], lst, paths, '>')\n",
    "    else:\n",
    "        if get_leaf_class_name(data['cut'].unique(), tree.value[list(lst[-2])[0]]) == class_name:\n",
    "            paths.add(tuple(lst[:-1]))\n",
    "        \n",
    "    lst.pop()\n",
    "    \n",
    "    \n",
    "def get_feature_value_pairs(tree, paths):\n",
    "    \n",
    "    pairs = []\n",
    "    for path in paths:\n",
    "        d = []\n",
    "        features = tree.feature\n",
    "        thresholds = tree.threshold\n",
    "\n",
    "        for i, p in enumerate(list(path[:-1])):\n",
    "            d.append((i, features[i], thresholds[i]))\n",
    "\n",
    "        pairs.append(d)\n",
    "        \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def rule_predict(class_name, rule):\n",
    "    pred = []\n",
    "    \n",
    "    for row in X_validation:\n",
    "        \n",
    "        valid = True\n",
    "        for condition in rule[:-1]:\n",
    "            condition = list(condition)\n",
    "            \n",
    "            if not get_truth(row[condition[1]], condition[2], condition[3]):\n",
    "                valid = False\n",
    "            \n",
    "        if valid:\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "# Function which computes rule accuracy based. It makes a classification report and takes\n",
    "# the precision value and returns it\n",
    "def compute_rule_accuracy(class_name, rule):\n",
    "    pred = rule_predict(class_name, rule)\n",
    "    report = classification_report(pred, Y_validation, output_dict = True)\n",
    "    \n",
    "    return round(report[str(class_name)]['precision'], 2)\n",
    "\n",
    "\n",
    "def prune_rule(class_name, rule):\n",
    "    max_accuracy = 0\n",
    "    final_rule = rule\n",
    "    \n",
    "    for i in range(len(rule[:-1])):\n",
    "        accuracy = compute_rule_accuracy(class_name, rule[i:])\n",
    "        \n",
    "        if accuracy > max_accuracy:\n",
    "            final_rule = rule[i:]\n",
    "            max_accuracy = accuracy\n",
    "           \n",
    "    return (max_accuracy, tuple(final_rule))\n",
    "\n",
    "\n",
    "def combine_rules(class_name, rf_model):\n",
    "    rules = set()\n",
    "    \n",
    "    for estimator in rf_model.estimators_:\n",
    "        get_paths_for(class_name, estimator.tree_, 0, [], rules, '<=')\n",
    "        \n",
    "    return rules\n",
    "\n",
    "\n",
    "def get_class_index(class_name):\n",
    "    for c, cls in enumerate(data['cut'].unique()):\n",
    "        if cls == class_name:\n",
    "            return c\n",
    "        \n",
    "        \n",
    "def get_rules_accuracy(class_name, rf_model, removeRedundancy = False):\n",
    "    rules = combine_rules(class_name, rf_model)\n",
    "    \n",
    "    if removeRedundancy:\n",
    "        rules = redundancy_condition_removal(rules)\n",
    "    \n",
    "    rules = list(rules)\n",
    "    \n",
    "    final_rules = set()\n",
    "    for rule in rules:\n",
    "        rule_ = [compute_rule_accuracy(get_class_index(class_name), rule), rule]\n",
    "        final_rules.add(tuple(rule_))\n",
    "        \n",
    "    return sorted(list(final_rules), reverse=True, key=lambda x: list(x)[0])\n",
    "    \n",
    "        \n",
    "def get_pruned_rules_accuracy(class_name, rf_model):\n",
    "    rules = list(combine_rules(class_name, rf_model))\n",
    "    \n",
    "    final_rules = set()\n",
    "    for rule in rules:\n",
    "        pruned = prune_rule(get_class_index(class_name), list(rule))\n",
    "        final_rules.add(tuple(pruned))\n",
    "    \n",
    "    return sorted(list(final_rules), reverse=True, key=lambda x: list(x)[0])\n",
    "\n",
    "\n",
    "def redundancy_condition_removal(rule_set):\n",
    "    output = set()\n",
    "    \n",
    "    for rule in list(rule_set):\n",
    "        \n",
    "        rule = list(rule)\n",
    "        for i, cond in enumerate(rule[:-1]):\n",
    "            cond = list(cond)\n",
    "            \n",
    "            for cond2 in rule[i + 1:-1]:\n",
    "                cond2 = list(cond2)\n",
    "                    \n",
    "                if cond[1] == cond2[1] and cond[2] == cond2[2]:\n",
    "                    if cond[2] == '>':\n",
    "                        cond[3] = (cond[3] if cond[3] > cond2[3] else cond2[3])\n",
    "                    else:\n",
    "                        cond[3] = (cond[3] if cond[3] < cond2[3] else cond2[3])\n",
    "                        \n",
    "                    # Assign changed rule to condition\n",
    "                    rule[i] = tuple(cond)\n",
    "                    \n",
    "                    # Remove redundant rule from list\n",
    "                    rule.remove(tuple(cond2))\n",
    "                \n",
    "        output.add(tuple(rule))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def create_big_or_rule(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += create_and_expression(rule)\n",
    "        \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" | \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def create_big_and_rule(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += create_and_expression(rule)\n",
    "        \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" & \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def combine_rule_using_and(rule_set):\n",
    "    output = \"\"\n",
    "    for i, rule in enumerate(list(rule_set)):\n",
    "        output += \"(\" + rule + \")\"\n",
    "            \n",
    "        if len(rule_set) - 1 != i:\n",
    "            output += \" & \"\n",
    "            \n",
    "    return output\n",
    "\n",
    "\n",
    "def combine_forest_rules(rf_model, class_name, r_dict, v_dict):\n",
    "    final_rule = set()\n",
    "    simplified_final_rule = set()\n",
    "    for estimator in rf_model.estimators_:\n",
    "    \n",
    "        rules = set()\n",
    "        get_paths_for(class_name, estimator.tree_, 0, [], rules, '<=')\n",
    "        \n",
    "        rules = redundancy_condition_removal(rules)\n",
    "        tree_rule = sympify(create_big_or_rule(rules), evaluate=False)\n",
    "        \n",
    "        final_rule.add(str(tree_rule))\n",
    "        simplified_final_rule.add(convert_to_function('&', expr(str(tree_rule)).to_cnf()))\n",
    "        \n",
    "        \n",
    "    return final_rule, simplified_final_rule\n",
    "\n",
    "\n",
    "def create_and_expression(rule):\n",
    "    output = \"\"\n",
    "    \n",
    "    for i, condition in enumerate(list(rule)[:-1]):\n",
    "        condition = list(condition)\n",
    "        key = str(condition[1]) + str(condition[3])\n",
    "        \n",
    "        var = \"A\" + uuid.uuid4().hex[:6].upper()\n",
    "        \n",
    "        if key in rule_dict:\n",
    "            if condition[2] != rule_dict[key][0]:\n",
    "                output += \"Not(\" + rule_dict[key][1] + \")\"\n",
    "            else:\n",
    "                output += rule_dict[key][1]\n",
    "        else:\n",
    "            expr = var + ' = ' + 'symbols(\\'' + (str(condition[1]) + condition[2] + str(condition[3])) + '\\')'\n",
    "            exec(expr)\n",
    "            \n",
    "            rule_dict[key] = [condition[2], var]\n",
    "            output += var\n",
    "        \n",
    "            # Also push to rule_dict where key is the variable name and value is the rule\n",
    "            var_dict[var] = condition\n",
    "        \n",
    "        if len(list(rule)[:-1]) - 1 != i:\n",
    "            output += \" & \"\n",
    "        \n",
    "    return \"(\" + output + \")\"\n",
    "\n",
    "\n",
    "def print_final_rule(simplified_rule):\n",
    "    simplified_rule = str(simplified_rule).split()\n",
    "    \n",
    "    final_rule = \"\"\n",
    "    for el in simplified_rule:\n",
    "        if el in ('&', '|'):\n",
    "            final_rule += \" \" + el + \" \"\n",
    "        else:\n",
    "            if \"~\" in el:\n",
    "                el = el.replace(\"~\", \"\")\n",
    "                el_ = el\n",
    "                \n",
    "                lb_count = el_.count('(')\n",
    "                if \"(\" in el_:\n",
    "                    el_ = el_.replace(\"(\", \"\")\n",
    "                \n",
    "                rb_count = el_.count(')')\n",
    "                if \")\" in el_:\n",
    "                    el_ = el_.replace(\")\", \"\")\n",
    "                \n",
    "                var = var_dict[str(el_)].copy()[1:]\n",
    "                if var[1] == '>':\n",
    "                    var[1] = '<='\n",
    "                else:\n",
    "                    var[1] = '>'\n",
    "                  \n",
    "                if lb_count == 0 and rb_count == 0:\n",
    "                    final_rule += str(tuple(var))\n",
    "                elif lb_count != 0 and rb_count == 0:\n",
    "                    final_rule += (\"(\" * lb_count) + str(tuple(var))\n",
    "                elif lb_count == 0 and rb_count != 0:\n",
    "                    final_rule += str(tuple(var)) + (\")\" * rb_count)\n",
    "            \n",
    "            elif \"(\" in el:\n",
    "                b_count = el.count('(')\n",
    "                \n",
    "                el = el.replace(\"(\", \"\")\n",
    "                final_rule += (\"(\" * b_count) + str(tuple(var_dict[str(el)][1:]))\n",
    "                \n",
    "            elif \")\" in el:\n",
    "                b_count = el.count(')')\n",
    "                \n",
    "                el = el.replace(\")\", \"\")\n",
    "                final_rule += str(tuple(var_dict[str(el)][1:])) + (\")\" * b_count)\n",
    "            \n",
    "            else:\n",
    "                final_rule += str(tuple(var_dict[str(el)][1:]))\n",
    "            \n",
    "    return final_rule\n",
    "\n",
    "\n",
    "def convert_to_function(sign, expr_):\n",
    "    rule = \"\"\n",
    "    for i, el in enumerate(expr_.xs):\n",
    "        if \"And\" in str(el):\n",
    "            rule += \"(\" + convert_to_function(\"&\", el) + \")\"\n",
    "        elif \"Or\" in str(el):\n",
    "            rule += \"(\" + convert_to_function(\"|\", el) + \")\"\n",
    "        else:\n",
    "            rule += str(el)\n",
    "            \n",
    "        if i != len(expr_.xs) - 1:\n",
    "            rule += \" \" + sign + \" \"\n",
    "            \n",
    "    return rule\n",
    "\n",
    "\n",
    "def get_valid_predicate(rule):\n",
    "    rule = rule.replace(\"&\", \"and\").replace(\"|\", \"or\").replace(\"0, '\", 'sepal_length_cm ').replace(\"1, '\", 'sepal_width_cm ')\n",
    "    rule = rule.replace(\"2, '\", 'petal_length_cm ').replace(\"3, '\", 'petal_width_cm ').replace(\"',\", \"\")\n",
    "    \n",
    "    return rule\n",
    "    \n",
    "    \n",
    "def predict_rule_class(rule_set):\n",
    "    X = X_train\n",
    "    Y = Y_train\n",
    "    \n",
    "    Z = predicate_rules_set_predict(rules_set, X_validation)\n",
    "    \n",
    "    print(accuracy_score(Y_validation, Z))\n",
    "    print(classification_report(Z, Y_validation))\n",
    "    \n",
    "    \n",
    "def compute_final_rule_accuracy(class_index, rule):\n",
    "    X = X_validation\n",
    "    Y = Y_validation\n",
    "    \n",
    "    # Classification report\n",
    "    Z = compute_rule_accuracy(class_index, rule, X)\n",
    "\n",
    "    report = classification_report(Z, Y, output_dict = True)\n",
    "    print(report[str(class_index)])\n",
    "    \n",
    "    \n",
    "def compute_rule_accuracy(class_name, rule, dataset):\n",
    "    \"\"\"This method allows you to evaluate the whole rule given by 'rule' parameter to 'class_name'\n",
    "    Returns an array of evaluated rule\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    # Store dataframe attribute names\n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    \n",
    "    # Create an ordered dictionary in order to keep the order when we take values for given columns\n",
    "    d_ = OrderedDict()\n",
    "    \n",
    "    # Create and optimize predicate given by the parameter\n",
    "    test = Predicate(rule)\n",
    "    s = OptimizedPredicateSet([test])\n",
    "    \n",
    "    for row in dataset:\n",
    "        \n",
    "        # Create dictionary consisting of attribute names and corresponding row values for them\n",
    "        for l, at in enumerate(df_columns):\n",
    "            d_[at] = row[l]\n",
    "        \n",
    "        # Evaluate rule with created dictionary\n",
    "        match = s.evaluate(dict(d_))\n",
    "            \n",
    "        # If the conditions from rule were met, append the class to final predictions array\n",
    "        if len(match):\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def attribute_rule_predict(class_name, rule, attr1, attr2, dataset):\n",
    "    \"\"\"Method used to get prediction only for two attributes given by 'attr1' and 'attr2' parameters\n",
    "    This method is mainly used mainly for plotting purposes\n",
    "    \"\"\" \n",
    "    \n",
    "    # Create an empty predictions array\n",
    "    pred = []\n",
    "    \n",
    "    # Create and optimize predicate given by the parameter\n",
    "    test = Predicate(rule)\n",
    "    s = OptimizedPredicateSet([test])\n",
    "    \n",
    "    # Store dataframe attribute names\n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    \n",
    "    # Create dictionary in which we will create the predicate\n",
    "    d_ = dict()\n",
    "    \n",
    "    for row in dataset:\n",
    "        \n",
    "        # Get the attribute names by indexes from df_columns.\n",
    "        d_[df_columns[attr1]] = row[0]\n",
    "        d_[df_columns[attr2]] = row[1]\n",
    "    \n",
    "        # Evaluate rule with created dictionary\n",
    "        match = s.evaluate(d_)\n",
    "            \n",
    "        # If the conditions from rule were met, append the class to final predictions array\n",
    "        if len(match):\n",
    "            pred.append(class_name)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "            \n",
    "    return pred\n",
    "\n",
    "\n",
    "def visualize_decision_boundaries(rule, attr1, attr2):\n",
    "    \"\"\"\n",
    "    This function is used to draw decision boundaries for 2 attributes which will be used to predict the output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dataset from validation data having only columns specified by paramters\n",
    "    X = X_validation[:, [attr1, attr2]]\n",
    "    Y = Y_validation\n",
    "\n",
    "    # Plotting decision regions\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    f, axarr = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Create prediction\n",
    "    ravel_ = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = np.array(attribute_rule_predict(1, rule, attr1, attr2, ravel_))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot predicted dots\n",
    "    axarr.contourf(xx, yy, Z, alpha=0.5)\n",
    "    axarr.scatter(X[:, 0], X[:, 1], c=Y, s=50, edgecolor='k')\n",
    "    axarr.set_title(\"When random forest is very sure\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def predicate_rules_set_predict(rules_set, dataset):\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    df_columns = list(data.columns.values[:-1])\n",
    "    d_ = OrderedDict()\n",
    "    \n",
    "    w_set = set()\n",
    "    for r in rules_set:\n",
    "        r = (r[0], OptimizedPredicateSet([Predicate(r[1])]))\n",
    "        w_set.add(r)\n",
    "        \n",
    "    for i, row in enumerate(dataset):\n",
    "        \n",
    "        \n",
    "        for l, at in enumerate(df_columns):\n",
    "            d_[at] = row[l]\n",
    "            \n",
    "        \n",
    "        j = 0\n",
    "        for r in w_set:\n",
    "            class_i = r[0]\n",
    "            rule_p = r[1]\n",
    "\n",
    "            match = rule_p.evaluate(dict(d_))\n",
    "\n",
    "            if len(match):\n",
    "                pred.append(class_i)\n",
    "                break\n",
    "        \n",
    "            j += 1\n",
    "            \n",
    "        if j == len(w_set):\n",
    "            pred.append(-1)\n",
    "        \n",
    "    return pred\n",
    "\n",
    "\n",
    "def redundancy_condition_removal_(rule_set):\n",
    "    output = set()\n",
    "    \n",
    "    for rule in list(rule_set):\n",
    "        \n",
    "        rule = list(rule)\n",
    "        for i, cond in enumerate(rule):\n",
    "            cond = list(cond)\n",
    "            \n",
    "            for cond2 in rule[i + 1:]:\n",
    "                cond2 = list(cond2)\n",
    "                    \n",
    "                if cond[0] == cond2[0] and cond[1] == cond2[1]:\n",
    "                    if cond[1] == '>':\n",
    "                        cond[2] = (cond[2] if cond[2] > cond2[2] else cond2[2])\n",
    "                    else:\n",
    "                        cond[2] = (cond[2] if cond[2] < cond2[2] else cond2[2])\n",
    "                        \n",
    "                    # Assign changed rule to condition\n",
    "                    rule[i] = tuple(cond)\n",
    "                    \n",
    "                    # Remove redundant rule from list\n",
    "                    rule.remove(tuple(cond2))\n",
    "                \n",
    "        output.add(tuple(rule))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def split_rules(rule_str):\n",
    "    redundant_rules_set = set()\n",
    "    composed_rules_set = set()\n",
    "    \n",
    "    rule = \"\"\n",
    "    stack = []\n",
    "    \n",
    "    for c in rule_str:\n",
    "        \n",
    "        if c in (' ', '&', '|') and len(stack) == 0:\n",
    "            continue\n",
    "            \n",
    "        rule += c\n",
    "        \n",
    "        if c == \"(\":\n",
    "            stack.append(c)\n",
    "        \n",
    "        if c == \")\" and len(stack) == 1:\n",
    "            stack.pop()\n",
    "            \n",
    "            if len(stack) == 0:\n",
    "                try:\n",
    "                    redundant_rules_set.add(eval(rule))\n",
    "                except:\n",
    "                    composed_rules_set.add(rule)\n",
    "            \n",
    "            rule = \"\"\n",
    "            \n",
    "        elif c == ')':\n",
    "            stack.pop()\n",
    "            \n",
    "    return redundant_rules_set, composed_rules_set\n",
    "\n",
    "\n",
    "def compose_final_rule(no_redundant_rules, composed_rules_set):\n",
    "    final_rule = \"\"\n",
    "    \n",
    "    for i, rule in enumerate(no_redundant_rules):\n",
    "        final_rule += str(rule) + \" & \"\n",
    "            \n",
    "    for i, rule in enumerate(composed_rules_set):\n",
    "        final_rule += rule\n",
    "        \n",
    "        if len(composed_rules_set) - 1 != i:\n",
    "            final_rule += \" & \"\n",
    "        \n",
    "    return final_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfclf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c878a453df5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvar_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_rules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_forest_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fair\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfclf' is not defined"
     ]
    }
   ],
   "source": [
    "rule_dict = {}\n",
    "var_dict = {}\n",
    "\n",
    "rules, s_rules = combine_forest_rules(rfclf, \"Fair\", rule_dict, var_dict)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = combine_rule_using_and(s_rules)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_validation, pred))\n",
    "print(classification_report(Y_validation, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_array = data_.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_tree(clf, data['cut'].unique(), feature_names_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_set = set()\n",
    "get_paths_for(\"Fair\", clf.tree_, 0, [], rules_set, '<=')\n",
    "rules_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_set = redundancy_condition_removal(rules_set)\n",
    "rules_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclf = RandomForestClassifier(n_estimators=5, max_depth=4)\n",
    "rfclf.fit(X_train, Y_train)\n",
    "\n",
    "pred = rfclf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = combine_rule_using_and(s_rules)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = expr(s).to_dnf()\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
